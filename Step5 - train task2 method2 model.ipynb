{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model for task 2 method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras \n",
    "\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense, Dropout,Input\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten,GlobalAveragePooling2D,BatchNormalization\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt \n",
    "from keras import regularizers\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobidity_file = pd.read_csv('../input/mobidity/morbidity.csv')\n",
    "mobidity_file\n",
    "mobidity_file['type'] = 3\n",
    "mobidity_file.loc[mobidity_file['Morbidity']==1,'type'] = 0\n",
    "mobidity_file.loc[(mobidity_file['Morbidity']==3) |(mobidity_file['Morbidity']==4) ,'type'] = 1\n",
    "mobidity_file.loc[(mobidity_file['Morbidity']==5) |(mobidity_file['Morbidity']==6) ,'type'] = 2\n",
    "y_train = np.array(mobidity_file['type'])[:999]\n",
    "y_test = np.array(mobidity_file['type'])[999:]\n",
    "# 10 most possible postive CT images\n",
    "\n",
    "# X_train = np.load('../input/task2trial2/train_10ct.npy')\n",
    "# X_test = np.load('../input/task2trial2/test_10ct.npy')\n",
    "\n",
    "# ten CT images selected from the middle\n",
    "X_train = np.load('../input/10middle-ct/train_10.npy')\n",
    "X_test = np.load('../input/10middle-ct/test_10.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete patients with suspected morbidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data\n",
    "keep = np.ones(y_train.shape, dtype=bool)\n",
    "for pos, val in enumerate(y_train):\n",
    "    if val ==3:\n",
    "        keep[pos] = False\n",
    "y_train = y_train[keep]\n",
    "X_train = X_train[keep]\n",
    "\n",
    "#for test data\n",
    "keep1 = np.ones(y_test.shape, dtype=bool)\n",
    "for pos, val in enumerate(y_test):\n",
    "    if val ==3:\n",
    "        keep1[pos] = False\n",
    "y_test = y_test[keep1]\n",
    "X_test= X_test[keep1]\n",
    "print(len(y_train))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# because the distribution of the suspected patients are not uniformly distributed. we resplit the data\n",
    "X = np.concatenate((X_train,X_test),axis=0)\n",
    "y = np.concatenate((y_train,y_test),axis=0)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train, y_test = train_test_split(X,y,test_size =0.2,random_state = 42,shuffle = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show examples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,8))\n",
    "x, y =5,2\n",
    "for i in range(10):\n",
    "    n=89\n",
    "    plt.subplot(y, x, i+1)\n",
    "    plt.imshow(X_train[n,:,:,i],cmap='gray')\n",
    "    plt.title('target: {}'.format(y_train[n]))\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solve imbalanced data problem with class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type0 = 0\n",
    "type1 = 0\n",
    "type2 = 0\n",
    "for i in y_train:\n",
    "    if i == 0:\n",
    "        type0+=1\n",
    "    elif i==1:\n",
    "        type1+=1\n",
    "    else:\n",
    "        type2+=1\n",
    "print(type0,type1,type2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_for_0 = (1 / type0)*(999)/3.0 \n",
    "weight_for_1 = (1 / type1)*(999)/3.0\n",
    "weight_for_2 = (1 / type2)*(999)/3.0\n",
    "class_weights = {0: weight_for_0, 1: weight_for_1, 2:weight_for_2}\n",
    "\n",
    "print('Weight for class 0: {:.2f}'.format(weight_for_0))\n",
    "print('Weight for class 1: {:.2f}'.format(weight_for_1))\n",
    "print('Weight for class 2: {:.2f}'.format(weight_for_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change y into a hot vestor\n",
    "y_train = keras.utils.to_categorical(y_train,3)\n",
    "y_test = keras.utils.to_categorical(y_test,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmention using ImageDataGenetator\n",
    "train = ImageDataGenerator(horizontal_flip=True,\n",
    "                            rotation_range=20)\n",
    "#                           zoom_range=1.2)\n",
    "\n",
    "test =  ImageDataGenerator(horizontal_flip=True,\n",
    "                          rotation_range=20)\n",
    "#                           zoom_range=1.2)\n",
    "\n",
    "train_generator = train.flow(X_train,y_train,batch_size=32)\n",
    "test_generator = test.flow(X_test,y_test,batch_size=32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Conv2D(input_shape=(256,256,10),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\",kernel_initializer='he_normal'))\n",
    "model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\",kernel_initializer='he_normal'))\n",
    "model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\",kernel_initializer='he_normal'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\",kernel_initializer='he_normal'))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\",kernel_initializer='he_normal'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# model.add(Dense(128, activation='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = VGG_Simple()\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(lr=0.001,decay=0.05),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "early_stopping_monitor = EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "\n",
    "epochs = 40\n",
    "\n",
    "history = model.fit(X_train,y_train,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          class_weight = class_weights,\n",
    "          callbacks=[early_stopping_monitor],\n",
    "          validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1,len(accuracy)+1)\n",
    "\n",
    "plt.plot(epochs, accuracy,'b', label='Training')\n",
    "plt.plot(epochs, val_accuracy, 'r', label='Test')\n",
    "plt.xlabel('Epoch', size=14)\n",
    "plt.ylabel('Accuracy', size=14)\n",
    "plt.xticks(np.arange(0,len(epochs), step=4))\n",
    "plt.title('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'b', label='Training')\n",
    "plt.plot(epochs, val_loss, 'r', label='Test')\n",
    "plt.xlabel('Epoch', size=14)\n",
    "plt.ylabel('Loss', size=14)\n",
    "plt.xticks(np.arange(0, len(epochs), step=4))\n",
    "plt.title('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save weigths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "trial = 'model_task2_10middle'\n",
    "\n",
    "statistics = {'train':(loss,accuracy), 'eval':(val_loss,val_accuracy)}\n",
    "json.dump(statistics, open(trial+'.json', 'w'))\n",
    "model.save_weights(trial+'.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comfusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "# convert one hot to vector\n",
    "Y_test = np.argmax(y_test, axis = 1)\n",
    "Y_pred = np.argmax(y_pred, axis = 1)\n",
    "\n",
    "cm1 = metrics.confusion_matrix(Y_test, Y_pred)\n",
    "cmap = sns.diverging_palette(220,10,center = \"light\", as_cmap=True)\n",
    "plt.figure(figsize=(9,9))\n",
    "sns.heatmap(cm1, annot=True, fmt=\".0f\", linewidths=.5, square=True, cmap=cmap)\n",
    "plt.ylabel('true number', size=17)\n",
    "plt.xlabel('predicted number', size=17)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
